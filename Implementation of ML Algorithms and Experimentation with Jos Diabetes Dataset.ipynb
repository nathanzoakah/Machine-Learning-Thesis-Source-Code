{"cells":[{"source":"# Import Libaries\n# Import Libaries\n#Base libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport seaborn as sns\nsns.set()\n\n# Libraries for Preprocessing\nfrom sklearn.preprocessing import StandardScaler\n#from imblearn.over_sampling import RandomOverSampler\n#from imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.impute import SimpleImputer\nimport missingno as msno\nfrom sklearn.model_selection import RepeatedStratifiedKFold,StratifiedKFold\n#from imblearn.pipeline import Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import RFE\n\n\n# Libraries for Machine Learning Algorithms\n#from sklearn.ensemble import RandomForestClassifier\n#from sklearn.svm import SVC\n#from sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\n\n# Scikit-learn version of algorithms implemented in this study \n#from sklearn.tree import DecisionTreeClassifier\n#from sklearn.naive_bayes import GaussianNB\n\n# Libraries  for Evaluation Metrics\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.metrics import plot_roc_curve, roc_auc_score, matthews_corrcoef\nfrom sklearn.metrics import precision_score, recall_score, roc_auc_score\n\n# Hyperparameter Tuning\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n# Others\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.datasets import make_classification\nimport pickle\n\n# Ensembling different Algorithms\nfrom sklearn.ensemble import StackingClassifier","metadata":{"executionTime":891,"lastSuccessfullyExecutedCode":"# Import Libaries\n# Import Libaries\n#Base libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport seaborn as sns\nsns.set()\n\n# Libraries for Preprocessing\nfrom sklearn.preprocessing import StandardScaler\n#from imblearn.over_sampling import RandomOverSampler\n#from imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.impute import SimpleImputer\nimport missingno as msno\nfrom sklearn.model_selection import RepeatedStratifiedKFold,StratifiedKFold\n#from imblearn.pipeline import Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import RFE\n\n\n# Libraries for Machine Learning Algorithms\n#from sklearn.ensemble import RandomForestClassifier\n#from sklearn.svm import SVC\n#from sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\n\n# Scikit-learn version of algorithms implemented in this study \n#from sklearn.tree import DecisionTreeClassifier\n#from sklearn.naive_bayes import GaussianNB\n\n# Libraries  for Evaluation Metrics\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.metrics import plot_roc_curve, roc_auc_score, matthews_corrcoef\nfrom sklearn.metrics import precision_score, recall_score, roc_auc_score\n\n# Hyperparameter Tuning\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n# Others\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.datasets import make_classification\nimport pickle\n\n# Ensembling different Algorithms\nfrom sklearn.ensemble import StackingClassifier"},"cell_type":"code","id":"186e8665-2812-47e6-bcfa-e0269be9fcf6","execution_count":2,"outputs":[]},{"source":"\n# Method to read file, process and divide dataset into X (Features) and y (label)\n\ndef read_process_divide(file):\n    data = pd.read_csv(file)\n    \n    # drop first column\n    data.drop(columns=data.columns[0], axis=1, inplace=True)\n    \n    # divide features and target\n    X = data.iloc[:,: -1]\n    y = data.iloc[:, -1]\n\n    return data, X , y\n","metadata":{"executionTime":114,"lastSuccessfullyExecutedCode":"\n# Method to read file, process and divide dataset into X (Features) and y (label)\n\ndef read_process_divide(file):\n    data = pd.read_csv(file)\n    \n    # drop first column\n    data.drop(columns=data.columns[0], axis=1, inplace=True)\n    \n    # divide features and target\n    X = data.iloc[:,: -1]\n    y = data.iloc[:, -1]\n\n    return data, X , y\n"},"cell_type":"code","id":"5d4194cc-71ca-4387-9a5c-642ef5cc61ad","execution_count":5,"outputs":[]},{"source":"diabetes_data, X, y = read_process_divide(\"diabetes_data_jos_urban_2012_no_missing_values_Updated_2.csv\")","metadata":{"executionTime":73,"lastSuccessfullyExecutedCode":"diabetes_data, X, y = read_process_divide(\"diabetes_data_jos_urban_2012_no_missing_values_Updated_2.csv\")"},"cell_type":"code","id":"e1cf8135-d9f4-438e-b6cc-ac50a37d180e","execution_count":6,"outputs":[]},{"source":"diabetes_data.shape","metadata":{"executionTime":91,"lastSuccessfullyExecutedCode":"diabetes_data.shape"},"cell_type":"code","id":"7c1d91bd-21f4-4313-9451-b7d80987e536","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"(746, 14)"},"metadata":{}}]},{"source":"### Logistic Regression Algorithm","metadata":{},"cell_type":"markdown","id":"3c862084-0fb0-43dc-bea9-5ea5cb16f2fc"},{"source":"from Logistic_Regression import LogisticRegression_implement","metadata":{"executionTime":82,"lastSuccessfullyExecutedCode":"from Logistic_Regression import LogisticRegression_implement"},"cell_type":"code","id":"6b031a86-656b-407b-91e4-a821a07129fd","execution_count":1,"outputs":[]},{"source":"sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=529)\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor train_idx, val_idx in sk.split(X, y):\n    # training set\n    X_tr = X.loc[train_idx]\n    y_tr = y.loc[train_idx]\n    \n    # testing set \n    X_val = X.loc[val_idx]\n    y_val = y.loc[val_idx]","metadata":{"executionTime":74,"lastSuccessfullyExecutedCode":"sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=529)\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor train_idx, val_idx in sk.split(X, y):\n    # training set\n    X_tr = X.loc[train_idx]\n    y_tr = y.loc[train_idx]\n    \n    # testing set \n    X_val = X.loc[val_idx]\n    y_val = y.loc[val_idx]"},"cell_type":"code","id":"ba049f10-278c-49dd-adb6-105c10d12445","execution_count":9,"outputs":[]},{"source":"y_val.value_counts()","metadata":{"executionTime":114,"lastSuccessfullyExecutedCode":"y_val.value_counts()"},"cell_type":"code","id":"677294c8-3016-40ff-8fa4-738e05a55f7f","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"0    65\n1     9\nName: Diagnosis, dtype: int64"},"metadata":{}}]},{"source":"sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=529)\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor train_idx, val_idx in sk.split(X, y):\n    # training set\n    X_tr = X.loc[train_idx]\n    y_tr = y.loc[train_idx]\n    \n    # testing set \n    X_val = X.loc[val_idx]\n    y_val = y.loc[val_idx]\n    \n    # Other preprocessing task\n    \n    # Class Balancing\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled =smote.fit_resample(X_tr, y_tr)\n\n    # Scaling\n    scaler = StandardScaler()\n    X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n    X_test_scaled = scaler.transform(X_val)\n\n    # PCA\n    pca = PCA(n_components=10)\n    X_train_resampled_scaled_pca = pca.fit_transform(X_train_resampled_scaled)\n    X_test_scaled_pca = pca.transform(X_test_scaled)\n    \n\n    # Fit Model on Train\n    clf_lr = LogisticRegression_implement()\n    clf_lr.fit(X_train_resampled_scaled_pca, y_train_resampled)\n    pred = clf_lr.predict(X_test_scaled_pca)\n    #pred_prob = clf.predict_proba(X_test_scaled_pca)[:, 1]\n    \n    auc_score = roc_auc_score(y_val, pred)\n    acc_score = accuracy_score(y_val, pred)\n    pre_score = precision_score(y_val, pred)\n    rcl_score = recall_score(y_val, pred)\n    mcc_score =  matthews_corrcoef(y_val, pred)\n    print(f\"======= Fold {fold} ========\")\n    print(f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\")\n    \n    fold += 1\n    aucs.append(auc_score)\n    accs.append(acc_score)\n    pres.append(pre_score)\n    rcls.append(rcl_score)\n    mccs.append(mcc_score)\n    \n    \noof_auc = np.mean(aucs)\nprint(f'Our out of fold AUC score is {oof_auc:0.4f}')\n    \noof_acc = np.mean(accs)\nprint(f'Our out of fold ACC score is {oof_acc:0.4f}')\n\noof_pre = np.mean(pres)\nprint(f'Our out of fold Precision score is {oof_pre:0.4f}')\n    \noof_rcl = np.mean(rcls)\nprint(f'Our out of fold Sensitivity score is {oof_rcl:0.4f}')\n\noof_mcc = np.mean(mccs)\nprint(f'Our out of fold MCC score is {oof_mcc:0.4f}')\n    ","metadata":{"executionTime":54432,"lastSuccessfullyExecutedCode":"sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=529)\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor train_idx, val_idx in sk.split(X, y):\n    # training set\n    X_tr = X.loc[train_idx]\n    y_tr = y.loc[train_idx]\n    \n    # testing set \n    X_val = X.loc[val_idx]\n    y_val = y.loc[val_idx]\n    \n    # Other preprocessing task\n    \n    # Class Balancing\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled =smote.fit_resample(X_tr, y_tr)\n\n    # Scaling\n    scaler = StandardScaler()\n    X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n    X_test_scaled = scaler.transform(X_val)\n\n    # PCA\n    pca = PCA(n_components=10)\n    X_train_resampled_scaled_pca = pca.fit_transform(X_train_resampled_scaled)\n    X_test_scaled_pca = pca.transform(X_test_scaled)\n    \n\n    # Fit Model on Train\n    clf_lr = LogisticRegression_implement()\n    clf_lr.fit(X_train_resampled_scaled_pca, y_train_resampled)\n    pred = clf_lr.predict(X_test_scaled_pca)\n    #pred_prob = clf.predict_proba(X_test_scaled_pca)[:, 1]\n    \n    auc_score = roc_auc_score(y_val, pred)\n    acc_score = accuracy_score(y_val, pred)\n    pre_score = precision_score(y_val, pred)\n    rcl_score = recall_score(y_val, pred)\n    mcc_score =  matthews_corrcoef(y_val, pred)\n    print(f\"======= Fold {fold} ========\")\n    print(f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\")\n    \n    fold += 1\n    aucs.append(auc_score)\n    accs.append(acc_score)\n    pres.append(pre_score)\n    rcls.append(rcl_score)\n    mccs.append(mcc_score)\n    \n    \noof_auc = np.mean(aucs)\nprint(f'Our out of fold AUC score is {oof_auc:0.4f}')\n    \noof_acc = np.mean(accs)\nprint(f'Our out of fold ACC score is {oof_acc:0.4f}')\n\noof_pre = np.mean(pres)\nprint(f'Our out of fold Precision score is {oof_pre:0.4f}')\n    \noof_rcl = np.mean(rcls)\nprint(f'Our out of fold Sensitivity score is {oof_rcl:0.4f}')\n\noof_mcc = np.mean(mccs)\nprint(f'Our out of fold MCC score is {oof_mcc:0.4f}')\n    "},"cell_type":"code","id":"4e7cd1aa-f35d-4b93-bee2-36b89135225d","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"======= Fold 1 ========\nOur accuracy on the validation set is 0.8400 and AUC is 0.7652\n======= Fold 2 ========\nOur accuracy on the validation set is 0.7600 and AUC is 0.7197\n======= Fold 3 ========\nOur accuracy on the validation set is 0.8400 and AUC is 0.8611\n======= Fold 4 ========\nOur accuracy on the validation set is 0.8800 and AUC is 0.8885\n======= Fold 5 ========\nOur accuracy on the validation set is 0.8000 and AUC is 0.8000\n======= Fold 6 ========\nOur accuracy on the validation set is 0.8667 and AUC is 0.8808\n======= Fold 7 ========\nOur accuracy on the validation set is 0.8378 and AUC is 0.8120\n======= Fold 8 ========\nOur accuracy on the validation set is 0.7703 and AUC is 0.6299\n======= Fold 9 ========\nOur accuracy on the validation set is 0.8108 and AUC is 0.7966\n======= Fold 10 ========\nOur accuracy on the validation set is 0.8243 and AUC is 0.8043\nOur out of fold AUC score is 0.7958\nOur out of fold ACC score is 0.8230\nOur out of fold Precision score is 0.3936\nOur out of fold Sensitivity score is 0.7600\nOur out of fold MCC score is 0.4578\n"}]},{"source":"y_val.shape","metadata":{"executionTime":69,"lastSuccessfullyExecutedCode":"y_val.shape"},"cell_type":"code","id":"b60adc06-f290-4311-97dd-91fde011ed24","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"(74,)"},"metadata":{}}]},{"source":"pred.shape","metadata":{"executionTime":258,"lastSuccessfullyExecutedCode":"pred.shape"},"cell_type":"code","id":"8afd1858-9588-440a-b1fd-055658fc2c94","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(74,)"},"metadata":{}}]},{"source":"y_train_resampled.value_counts()","metadata":{"executionTime":122,"lastSuccessfullyExecutedCode":"y_train_resampled.value_counts()"},"cell_type":"code","id":"b014ba40-10d2-461c-a046-f944f035e225","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"0    588\n1    588\nName: Diagnosis_2, dtype: int64"},"metadata":{}}]},{"source":"# Save Logistic Regression Model\npickle.dump(clf_lr, open(\"clf_model_lr.pkl\", \"wb\"))","metadata":{"executionTime":122,"lastSuccessfullyExecutedCode":"# Save Logistic Regression Model\npickle.dump(clf_lr, open(\"clf_model_lr.pkl\", \"wb\"))"},"cell_type":"code","id":"40bd7a99-b4e9-419d-b6fe-49e719867b18","execution_count":8,"outputs":[]},{"source":"# Load saved Logistic Regression model\nclf_model_lr  = pickle.load(open(\"clf_model_lr.pkl\", \"rb\"))","metadata":{"executionTime":282,"lastSuccessfullyExecutedCode":"# Load saved Logistic Regression model\nclf_model_lr  = pickle.load(open(\"clf_model_lr.pkl\", \"rb\"))"},"cell_type":"code","id":"368c6759-11af-4fc8-a76c-5b37ec3cd698","execution_count":9,"outputs":[]},{"source":"### Naive Bayes Algorithm","metadata":{},"cell_type":"markdown","id":"1dd85a38-36db-4db9-9684-8a4af05e064d"},{"source":"from Naive_Bayes import NaiveBayes","metadata":{"executionTime":87,"lastSuccessfullyExecutedCode":"from Naive_Bayes import NaiveBayes"},"cell_type":"code","id":"9ad500d3-ad6d-4bb0-a971-909073d53903","execution_count":13,"outputs":[]},{"source":"sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=529)\n\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor train_idx, val_idx in sk.split(X, y):\n    # training set\n    X_tr = X.loc[train_idx]\n    y_tr = y.loc[train_idx]\n    \n    # testing set \n    X_val = X.loc[val_idx]\n    y_val = y.loc[val_idx]\n    \n    # Other preprocessing task\n    \n    # Class Balancing\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled =smote.fit_resample(X_tr, y_tr)\n\n    # Scaling\n    scaler = StandardScaler()\n    X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n    X_test_scaled = scaler.transform(X_val)\n\n    # PCA\n    pca = PCA(n_components=10)\n    X_train_resampled_scaled_pca = pca.fit_transform(X_train_resampled_scaled)\n    X_test_scaled_pca = pca.transform(X_test_scaled)\n    \n\n    # Fit Model on Train\n    clf_nb = NaiveBayes()\n    clf_nb.fit(X_train_resampled_scaled_pca, y_train_resampled)\n    pred = clf_nb.predict(X_test_scaled_pca)\n    #pred_prob = clf.predict_proba(X_test_scaled_pca)[:, 1]\n    \n    auc_score = roc_auc_score(y_val, pred)\n    acc_score = accuracy_score(y_val, pred)\n    pre_score = precision_score(y_val, pred)\n    rcl_score = recall_score(y_val, pred)\n    mcc_score =  matthews_corrcoef(y_val, pred)\n    print(f\"======= Fold {fold} ========\")\n    print(f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\")\n    \n    fold += 1\n    aucs.append(auc_score)\n    accs.append(acc_score)\n    pres.append(pre_score)\n    rcls.append(rcl_score)\n    mccs.append(mcc_score)\n    \n    \noof_auc = np.mean(aucs)\nprint(f'Our out of fold AUC score is {oof_auc:0.4f}')\n    \noof_acc = np.mean(accs)\nprint(f'Our out of fold ACC score is {oof_acc:0.4f}')\n\noof_pre = np.mean(pres)\nprint(f'Our out of fold Precision score is {oof_pre:0.4f}')\n    \noof_rcl = np.mean(rcls)\nprint(f'Our out of fold Sensitivity score is {oof_rcl:0.4f}')\n\noof_mcc = np.mean(mccs)\nprint(f'Our out of fold MCC score is {oof_mcc:0.4f}')\n    ","metadata":{"executionTime":2525,"lastSuccessfullyExecutedCode":"sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=529)\n\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor train_idx, val_idx in sk.split(X, y):\n    # training set\n    X_tr = X.loc[train_idx]\n    y_tr = y.loc[train_idx]\n    \n    # testing set \n    X_val = X.loc[val_idx]\n    y_val = y.loc[val_idx]\n    \n    # Other preprocessing task\n    \n    # Class Balancing\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled =smote.fit_resample(X_tr, y_tr)\n\n    # Scaling\n    scaler = StandardScaler()\n    X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n    X_test_scaled = scaler.transform(X_val)\n\n    # PCA\n    pca = PCA(n_components=10)\n    X_train_resampled_scaled_pca = pca.fit_transform(X_train_resampled_scaled)\n    X_test_scaled_pca = pca.transform(X_test_scaled)\n    \n\n    # Fit Model on Train\n    clf_nb = NaiveBayes()\n    clf_nb.fit(X_train_resampled_scaled_pca, y_train_resampled)\n    pred = clf_nb.predict(X_test_scaled_pca)\n    #pred_prob = clf.predict_proba(X_test_scaled_pca)[:, 1]\n    \n    auc_score = roc_auc_score(y_val, pred)\n    acc_score = accuracy_score(y_val, pred)\n    pre_score = precision_score(y_val, pred)\n    rcl_score = recall_score(y_val, pred)\n    mcc_score =  matthews_corrcoef(y_val, pred)\n    print(f\"======= Fold {fold} ========\")\n    print(f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\")\n    \n    fold += 1\n    aucs.append(auc_score)\n    accs.append(acc_score)\n    pres.append(pre_score)\n    rcls.append(rcl_score)\n    mccs.append(mcc_score)\n    \n    \noof_auc = np.mean(aucs)\nprint(f'Our out of fold AUC score is {oof_auc:0.4f}')\n    \noof_acc = np.mean(accs)\nprint(f'Our out of fold ACC score is {oof_acc:0.4f}')\n\noof_pre = np.mean(pres)\nprint(f'Our out of fold Precision score is {oof_pre:0.4f}')\n    \noof_rcl = np.mean(rcls)\nprint(f'Our out of fold Sensitivity score is {oof_rcl:0.4f}')\n\noof_mcc = np.mean(mccs)\nprint(f'Our out of fold MCC score is {oof_mcc:0.4f}')\n    "},"cell_type":"code","id":"a1a84f1d-81f6-4991-ac10-9b3c14b87b28","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"======= Fold 1 ========\nOur accuracy on the validation set is 0.8800 and AUC is 0.6439\n======= Fold 2 ========\nOur accuracy on the validation set is 0.9200 and AUC is 0.6667\n======= Fold 3 ========\nOur accuracy on the validation set is 0.9733 and AUC is 0.9369\n======= Fold 4 ========\nOur accuracy on the validation set is 0.9200 and AUC is 0.7423\n======= Fold 5 ========\nOur accuracy on the validation set is 0.8800 and AUC is 0.6769\n======= Fold 6 ========\nOur accuracy on the validation set is 0.8933 and AUC is 0.6846\n======= Fold 7 ========\nOur accuracy on the validation set is 0.8649 and AUC is 0.7795\n======= Fold 8 ========\nOur accuracy on the validation set is 0.8919 and AUC is 0.6034\n======= Fold 9 ========\nOur accuracy on the validation set is 0.9054 and AUC is 0.6590\n======= Fold 10 ========\nOur accuracy on the validation set is 0.9459 and AUC is 0.8256\nOur out of fold AUC score is 0.7219\nOur out of fold ACC score is 0.9075\nOur out of fold Precision score is 0.7196\nOur out of fold Sensitivity score is 0.4744\nOur out of fold MCC score is 0.5265\n"}]},{"source":"# Save Naive Bayes Model\npickle.dump(clf_nb, open(\"clf_model_nb.pkl\", \"wb\"))","metadata":{"executionTime":217,"lastSuccessfullyExecutedCode":"# Save Naive Bayes Model\npickle.dump(clf_nb, open(\"clf_model_nb.pkl\", \"wb\"))"},"cell_type":"code","id":"50213bb3-894f-4d84-ba61-0481f9946cc8","execution_count":15,"outputs":[]},{"source":"# Load saved Naive Bayes model\nclf_model_nb  = pickle.load(open(\"clf_model_nb.pkl\", \"rb\"))","metadata":{"executionTime":371,"lastSuccessfullyExecutedCode":"# Load saved Naive Bayes model\nclf_model_nb  = pickle.load(open(\"clf_model_nb.pkl\", \"rb\"))"},"cell_type":"code","id":"2775f478-f575-42bb-87f5-28f426b6c2b6","execution_count":10,"outputs":[]},{"source":"### Linear Support Vector Machine","metadata":{},"cell_type":"markdown","id":"29353c8c-ecb8-4819-b662-d8356a7572db"},{"source":"from Linear_SVM import SVM","metadata":{"executionTime":152,"lastSuccessfullyExecutedCode":"from Linear_SVM import SVM"},"cell_type":"code","id":"d7cd727a-f4e8-408f-8097-4c063dd0a3e7","execution_count":16,"outputs":[]},{"source":"rsk = RepeatedStratifiedKFold(n_splits=10, random_state=529)\n\ndiabetes_data, X, y = read_process_divide(\"diabetes_data_jos_urban_2012_no_missing_values_Updated_2.csv\")\n\ny = np.where(y == 0, -1, 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor i in range(10):\n    \n    # Other preprocessing task\n    \n    # Class Balancing\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled =smote.fit_resample(X_train, y_train)\n    \n\n    # Scaling\n    scaler = StandardScaler()\n    X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n    X_test_scaled = scaler.transform(X_test)\n\n    # PCA\n    pca = PCA(n_components=10)\n    X_train_resampled_scaled_pca = pca.fit_transform(X_train_resampled_scaled)\n    X_test_scaled_pca = pca.transform(X_test_scaled)\n    \n\n    # Fit Model on Train\n    clf_svm = SVM()\n    clf_svm.fit(X_train_resampled_scaled_pca, y_train_resampled)\n    pred = clf_svm.predict(X_test_scaled_pca)\n    #pred_prob = clf.predict_proba(X_test_scaled_pca)[:, 1]\n    \n    auc_score = roc_auc_score(y_test, pred)\n    acc_score = accuracy_score(y_test, pred)\n    pre_score = precision_score(y_test, pred, average='micro')\n    rcl_score = recall_score(y_test, pred, average='micro')\n    mcc_score =  matthews_corrcoef(y_test, pred)\n    print(f\"======= Fold {fold} ========\")\n    print(f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\")\n    \n    fold += 1\n    aucs.append(auc_score)\n    accs.append(acc_score)\n    pres.append(pre_score)\n    rcls.append(rcl_score)\n    mccs.append(mcc_score)\n    \n    \noof_auc = np.mean(aucs)\nprint(f'Our out of fold AUC score is {oof_auc:0.4f}')\n    \noof_acc = np.mean(accs)\nprint(f'Our out of fold ACC score is {oof_acc:0.4f}')\n\noof_pre = np.mean(pres)\nprint(f'Our out of fold Precision score is {oof_pre:0.4f}')\n    \noof_rcl = np.mean(rcls)\nprint(f'Our out of fold Sensitivity score is {oof_rcl:0.4f}')\n\noof_mcc = np.mean(mccs)\nprint(f'Our out of fold MCC score is {oof_mcc:0.4f}')","metadata":{"executionTime":53256,"lastSuccessfullyExecutedCode":"rsk = RepeatedStratifiedKFold(n_splits=10, random_state=529)\n\ndiabetes_data, X, y = read_process_divide(\"diabetes_data_jos_urban_2012_no_missing_values_Updated_2.csv\")\n\ny = np.where(y == 0, -1, 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor i in range(10):\n    \n    # Other preprocessing task\n    \n    # Class Balancing\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled =smote.fit_resample(X_train, y_train)\n    \n\n    # Scaling\n    scaler = StandardScaler()\n    X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n    X_test_scaled = scaler.transform(X_test)\n\n    # PCA\n    pca = PCA(n_components=10)\n    X_train_resampled_scaled_pca = pca.fit_transform(X_train_resampled_scaled)\n    X_test_scaled_pca = pca.transform(X_test_scaled)\n    \n\n    # Fit Model on Train\n    clf_svm = SVM()\n    clf_svm.fit(X_train_resampled_scaled_pca, y_train_resampled)\n    pred = clf_svm.predict(X_test_scaled_pca)\n    #pred_prob = clf.predict_proba(X_test_scaled_pca)[:, 1]\n    \n    auc_score = roc_auc_score(y_test, pred)\n    acc_score = accuracy_score(y_test, pred)\n    pre_score = precision_score(y_test, pred, average='micro')\n    rcl_score = recall_score(y_test, pred, average='micro')\n    mcc_score =  matthews_corrcoef(y_test, pred)\n    print(f\"======= Fold {fold} ========\")\n    print(f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\")\n    \n    fold += 1\n    aucs.append(auc_score)\n    accs.append(acc_score)\n    pres.append(pre_score)\n    rcls.append(rcl_score)\n    mccs.append(mcc_score)\n    \n    \noof_auc = np.mean(aucs)\nprint(f'Our out of fold AUC score is {oof_auc:0.4f}')\n    \noof_acc = np.mean(accs)\nprint(f'Our out of fold ACC score is {oof_acc:0.4f}')\n\noof_pre = np.mean(pres)\nprint(f'Our out of fold Precision score is {oof_pre:0.4f}')\n    \noof_rcl = np.mean(rcls)\nprint(f'Our out of fold Sensitivity score is {oof_rcl:0.4f}')\n\noof_mcc = np.mean(mccs)\nprint(f'Our out of fold MCC score is {oof_mcc:0.4f}')"},"cell_type":"code","id":"e262e4c1-347f-48da-b4ef-1a700afb4b9e","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":"======= Fold 1 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\n======= Fold 2 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\n======= Fold 3 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\n======= Fold 4 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\n======= Fold 5 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\n======= Fold 6 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\n======= Fold 7 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\n======= Fold 8 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\n======= Fold 9 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\n======= Fold 10 ========\nOur accuracy on the validation set is 0.9241 and AUC is 0.9108\nOur out of fold AUC score is 0.9108\nOur out of fold ACC score is 0.9241\nOur out of fold Precision score is 0.9241\nOur out of fold Sensitivity score is 0.9241\nOur out of fold MCC score is 0.6541\n"}]},{"source":"y_test.shape","metadata":{"executionTime":100,"lastSuccessfullyExecutedCode":"y_test.shape"},"cell_type":"code","id":"b46cc0b1-2f22-48b6-a74b-defa626f140b","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"(224,)"},"metadata":{}}]},{"source":"pred.shape","metadata":{"executionTime":465,"lastSuccessfullyExecutedCode":"pred.shape"},"cell_type":"code","id":"2aadc155-b11b-4f9b-914a-a03b864ab100","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"(224,)"},"metadata":{}}]},{"source":"sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=529)\n\ndiabetes_data, X, y = read_process_divide(\"diabetes_data_jos_urban_2012_no_missing_values_Updated_2.csv\")\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor train_idx, val_idx in sk.split(X, y):\n    # training set\n    X_tr = X.loc[train_idx]\n    y_tr = y.loc[train_idx]\n    \n    # testing set \n    X_val = X.loc[val_idx]\n    y_val = y.loc[val_idx]\n    \n    \n    #Convert\n    y_tr = np.where(y_tr == 0, -1, 1)\n    y_val = np.where(y_val == 0, -1, 1)\n    \n    # Other preprocessing task\n    \n    # Class Balancing\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled =smote.fit_resample(X_tr, y_tr)\n\n    # Scaling\n    scaler = StandardScaler()\n    X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n    X_test_scaled = scaler.transform(X_val)\n\n    # PCA\n    pca = PCA(n_components=10)\n    X_train_resampled_scaled_pca = pca.fit_transform(X_train_resampled_scaled)\n    X_test_scaled_pca = pca.transform(X_test_scaled)\n    \n\n    # Fit Model on Train\n    clf_svm = SVM()\n    clf_svm.fit(X_train_resampled_scaled_pca, y_train_resampled)\n    pred = clf_svm.predict(X_test_scaled_pca)\n    #pred_prob = clf.predict_proba(X_test_scaled_pca)[:, 1]\n    \n    auc_score = roc_auc_score(y_val, pred)\n    acc_score = accuracy_score(y_val, pred)\n    pre_score = precision_score(y_val, pred)\n    rcl_score = recall_score(y_val, pred)\n    mcc_score =  matthews_corrcoef(y_val, pred)\n    print(f\"======= Fold {fold} ========\")\n    print(f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\")\n    \n    fold += 1\n    aucs.append(auc_score)\n    accs.append(acc_score)\n    pres.append(pre_score)\n    rcls.append(rcl_score)\n    mccs.append(mcc_score)\n    \n    \noof_auc = np.mean(aucs)\nprint(f'Our out of fold AUC score is {oof_auc:0.4f}')\n    \noof_acc = np.mean(accs)\nprint(f'Our out of fold ACC score is {oof_acc:0.4f}')\n\noof_pre = np.mean(pres)\nprint(f'Our out of fold Precision score is {oof_pre:0.4f}')\n    \noof_rcl = np.mean(rcls)\nprint(f'Our out of fold Sensitivity score is {oof_rcl:0.4f}')\n\noof_mcc = np.mean(mccs)\nprint(f'Our out of fold MCC score is {oof_mcc:0.4f}')\n    ","metadata":{"executionTime":66318,"lastSuccessfullyExecutedCode":"sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=529)\n\ndiabetes_data, X, y = read_process_divide(\"diabetes_data_jos_urban_2012_no_missing_values_Updated_2.csv\")\n\nfold = 1\naucs = []\naccs = []\npres = []\nrcls = []\nmccs = []\n\nfor train_idx, val_idx in sk.split(X, y):\n    # training set\n    X_tr = X.loc[train_idx]\n    y_tr = y.loc[train_idx]\n    \n    # testing set \n    X_val = X.loc[val_idx]\n    y_val = y.loc[val_idx]\n    \n    \n    #Convert\n    y_tr = np.where(y_tr == 0, -1, 1)\n    y_val = np.where(y_val == 0, -1, 1)\n    \n    # Other preprocessing task\n    \n    # Class Balancing\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled =smote.fit_resample(X_tr, y_tr)\n\n    # Scaling\n    scaler = StandardScaler()\n    X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n    X_test_scaled = scaler.transform(X_val)\n\n    # PCA\n    pca = PCA(n_components=10)\n    X_train_resampled_scaled_pca = pca.fit_transform(X_train_resampled_scaled)\n    X_test_scaled_pca = pca.transform(X_test_scaled)\n    \n\n    # Fit Model on Train\n    clf_svm = SVM()\n    clf_svm.fit(X_train_resampled_scaled_pca, y_train_resampled)\n    pred = clf_svm.predict(X_test_scaled_pca)\n    #pred_prob = clf.predict_proba(X_test_scaled_pca)[:, 1]\n    \n    auc_score = roc_auc_score(y_val, pred)\n    acc_score = accuracy_score(y_val, pred)\n    pre_score = precision_score(y_val, pred)\n    rcl_score = recall_score(y_val, pred)\n    mcc_score =  matthews_corrcoef(y_val, pred)\n    print(f\"======= Fold {fold} ========\")\n    print(f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\")\n    \n    fold += 1\n    aucs.append(auc_score)\n    accs.append(acc_score)\n    pres.append(pre_score)\n    rcls.append(rcl_score)\n    mccs.append(mcc_score)\n    \n    \noof_auc = np.mean(aucs)\nprint(f'Our out of fold AUC score is {oof_auc:0.4f}')\n    \noof_acc = np.mean(accs)\nprint(f'Our out of fold ACC score is {oof_acc:0.4f}')\n\noof_pre = np.mean(pres)\nprint(f'Our out of fold Precision score is {oof_pre:0.4f}')\n    \noof_rcl = np.mean(rcls)\nprint(f'Our out of fold Sensitivity score is {oof_rcl:0.4f}')\n\noof_mcc = np.mean(mccs)\nprint(f'Our out of fold MCC score is {oof_mcc:0.4f}')\n    "},"cell_type":"code","id":"28fdf89b-8f88-468e-8594-f5a1d1fbbf9a","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"======= Fold 1 ========\nOur accuracy on the validation set is 0.8667 and AUC is 0.8283\n======= Fold 2 ========\nOur accuracy on the validation set is 0.8933 and AUC is 0.8434\n======= Fold 3 ========\nOur accuracy on the validation set is 0.9200 and AUC is 0.9545\n======= Fold 4 ========\nOur accuracy on the validation set is 0.8933 and AUC is 0.8962\n======= Fold 5 ========\nOur accuracy on the validation set is 0.9333 and AUC is 0.9615\n======= Fold 6 ========\nOur accuracy on the validation set is 0.9067 and AUC is 0.9038\n======= Fold 7 ========\nOur accuracy on the validation set is 0.9189 and AUC is 0.9538\n======= Fold 8 ========\nOur accuracy on the validation set is 0.8514 and AUC is 0.7718\n======= Fold 9 ========\nOur accuracy on the validation set is 0.8784 and AUC is 0.8829\n======= Fold 10 ========\nOur accuracy on the validation set is 0.9054 and AUC is 0.8983\nOur out of fold AUC score is 0.8895\nOur out of fold ACC score is 0.8967\nOur out of fold Precision score is 0.5534\nOur out of fold Sensitivity score is 0.8800\nOur out of fold MCC score is 0.6454\n"}]},{"source":"# Save Linear Support Vector Machine Model\npickle.dump(clf_svm, open(\"clf_model_svm.pkl\", \"wb\"))","metadata":{"executionTime":70,"lastSuccessfullyExecutedCode":"# Save Linear Support Vector Machine Model\npickle.dump(clf_svm, open(\"clf_model_svm.pkl\", \"wb\"))"},"cell_type":"code","id":"ad8262bc-519e-43ac-854e-541b50f65790","execution_count":23,"outputs":[]},{"source":"# Load saved Logistic Regression model\nclf_model_svm  = pickle.load(open(\"clf_model_svm.pkl\", \"rb\"))","metadata":{"executionTime":71,"lastSuccessfullyExecutedCode":"# Load saved Logistic Regression model\nclf_model_svm  = pickle.load(open(\"clf_model_svm.pkl\", \"rb\"))"},"cell_type":"code","id":"1f5be733-702b-4cb8-9c67-a205fa8ca7ed","execution_count":12,"outputs":[]},{"source":"### Stacked Ensemble Method(SEM) implemented Algorithms","metadata":{},"cell_type":"markdown","id":"498235e6-e3a3-4e77-8d6a-04d8abb4fea5"},{"source":"##Stacked Ensemble Method\n\nestimator_list = [\n    (\"Logistic Regression\", clf_model_lr),\n    (\"Naive Bayes\", clf_model_nb),\n    (\"SVM\", clf_model_svm)\n    \n]\n","metadata":{"executionTime":485,"lastSuccessfullyExecutedCode":"##Stacked Ensemble Method\n\nestimator_list = [\n    (\"Logistic Regression\", clf_model_lr),\n    (\"Naive Bayes\", clf_model_nb),\n    (\"SVM\", clf_model_svm)\n    \n]\n"},"cell_type":"code","id":"6a204714-031c-4458-8c93-a6874ae1fc67","execution_count":25,"outputs":[]},{"source":"# Build stack model\nstacked_model = StackingClassifier(\n    estimators=estimator_list, final_estimator = LogisticRegression_implement())","metadata":{"executionTime":76,"lastSuccessfullyExecutedCode":"# Build stack model\nstacked_model = StackingClassifier(\n    estimators=estimator_list, final_estimator = LogisticRegression_implement())"},"cell_type":"code","id":"93aacb28-e853-4abb-b371-958fe8503973","execution_count":26,"outputs":[]},{"source":"stacked_model","metadata":{"executionTime":272,"lastSuccessfullyExecutedCode":"stacked_model"},"cell_type":"code","id":"241a9585-c70e-4800-bcdc-8b892f007eec","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"StackingClassifier(estimators=[('Logistic Regression',\n                                <Logistic_Regression.LogisticRegression_implement object at 0x7fe9d2b54c10>),\n                               ('Naive Bayes',\n                                <Naive_Bayes.NaiveBayes object at 0x7fe9d29a5eb0>),\n                               ('SVM',\n                                <Linear_SVM.SVM object at 0x7fe9d2a48b50>)],\n                   final_estimator=<Logistic_Regression.LogisticRegression_implement object at 0x7fe9c48a4eb0>)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;Logistic Regression&#x27;,\n                                &lt;Logistic_Regression.LogisticRegression_implement object at 0x7fe9d2b54c10&gt;),\n                               (&#x27;Naive Bayes&#x27;,\n                                &lt;Naive_Bayes.NaiveBayes object at 0x7fe9d29a5eb0&gt;),\n                               (&#x27;SVM&#x27;,\n                                &lt;Linear_SVM.SVM object at 0x7fe9d2a48b50&gt;)],\n                   final_estimator=&lt;Logistic_Regression.LogisticRegression_implement object at 0x7fe9c48a4eb0&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;Logistic Regression&#x27;,\n                                &lt;Logistic_Regression.LogisticRegression_implement object at 0x7fe9d2b54c10&gt;),\n                               (&#x27;Naive Bayes&#x27;,\n                                &lt;Naive_Bayes.NaiveBayes object at 0x7fe9d29a5eb0&gt;),\n                               (&#x27;SVM&#x27;,\n                                &lt;Linear_SVM.SVM object at 0x7fe9d2a48b50&gt;)],\n                   final_estimator=&lt;Logistic_Regression.LogisticRegression_implement object at 0x7fe9c48a4eb0&gt;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Logistic Regression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression_implement</label><div class=\"sk-toggleable__content\"><pre>&lt;Logistic_Regression.LogisticRegression_implement object at 0x7fe9d2b54c10&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Naive Bayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NaiveBayes</label><div class=\"sk-toggleable__content\"><pre>&lt;Naive_Bayes.NaiveBayes object at 0x7fe9d29a5eb0&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVM</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVM</label><div class=\"sk-toggleable__content\"><pre>&lt;Linear_SVM.SVM object at 0x7fe9d2a48b50&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression_implement</label><div class=\"sk-toggleable__content\"><pre>&lt;Logistic_Regression.LogisticRegression_implement object at 0x7fe9c48a4eb0&gt;</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"source":"","metadata":{"executionTime":99,"lastSuccessfullyExecutedCode":""},"cell_type":"code","id":"7da8621c-8481-4557-a15d-0dfb6ec1f8bf","execution_count":28,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}